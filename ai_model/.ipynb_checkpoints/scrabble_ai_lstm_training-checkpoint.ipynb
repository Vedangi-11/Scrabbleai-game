{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9ab0a8-2bb8-49a8-b772-7c34735fe935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\scrabble-ai\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "✅ Data shape: (1000, 15, 15) (1000,)\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\scrabble-ai\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 15, 64)            20480     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 64)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33985 (132.75 KB)\n",
      "Trainable params: 33985 (132.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\scrabble-ai\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\scrabble-ai\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "57/57 [==============================] - 11s 48ms/step - loss: 0.0412 - mae: 0.1548 - val_loss: 0.0160 - val_mae: 0.0977\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 0.0187 - mae: 0.1088 - val_loss: 0.0157 - val_mae: 0.0956\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 21ms/step - loss: 0.0169 - mae: 0.1042 - val_loss: 0.0155 - val_mae: 0.0980\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 0.0160 - mae: 0.1014 - val_loss: 0.0154 - val_mae: 0.0984\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 0.0152 - mae: 0.0974 - val_loss: 0.0148 - val_mae: 0.0981\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 21ms/step - loss: 0.0156 - mae: 0.0995 - val_loss: 0.0147 - val_mae: 0.0960\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 23ms/step - loss: 0.0150 - mae: 0.0994 - val_loss: 0.0163 - val_mae: 0.1035\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 0.0149 - mae: 0.0971 - val_loss: 0.0185 - val_mae: 0.1068\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 1s 23ms/step - loss: 0.0150 - mae: 0.0980 - val_loss: 0.0151 - val_mae: 0.0983\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.0150 - mae: 0.0992 - val_loss: 0.0160 - val_mae: 0.1021\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 0.0143 - mae: 0.0958 - val_loss: 0.0176 - val_mae: 0.1052\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 1s 25ms/step - loss: 0.0144 - mae: 0.0956 - val_loss: 0.0149 - val_mae: 0.0982\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 0.0139 - mae: 0.0949 - val_loss: 0.0161 - val_mae: 0.1025\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.0141 - mae: 0.0953 - val_loss: 0.0181 - val_mae: 0.1064\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.0141 - mae: 0.0954 - val_loss: 0.0173 - val_mae: 0.1047\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 2s 29ms/step - loss: 0.0145 - mae: 0.0967 - val_loss: 0.0150 - val_mae: 0.0977\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 2s 29ms/step - loss: 0.0137 - mae: 0.0932 - val_loss: 0.0155 - val_mae: 0.0996\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 1s 25ms/step - loss: 0.0131 - mae: 0.0924 - val_loss: 0.0164 - val_mae: 0.1034\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 0.0140 - mae: 0.0943 - val_loss: 0.0222 - val_mae: 0.1194\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 1s 21ms/step - loss: 0.0147 - mae: 0.0975 - val_loss: 0.0182 - val_mae: 0.1084\n",
      "✅ Training complete.\n",
      "✅ LSTM model saved to model/model_weights_lstm.h5\n",
      "✅ Tokenizer saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\scrabble-ai\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import random\n",
    "letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "def generate_board_grid():\n",
    "    \"\"\"\n",
    "    Create a 15x15 Scrabble-like grid where each cell is a letter (A-Z) or empty.\n",
    "    We'll encode letters as 1–26 and empty as 0.\n",
    "    \"\"\"\n",
    "    board = np.zeros((15, 15))\n",
    "    for i in range(15):\n",
    "        for j in range(15):\n",
    "            if random.random() < 0.3:  # ~30% filled\n",
    "                board[i, j] = ord(random.choice(letters)) - ord('A') + 1\n",
    "    return board\n",
    "def estimate_score_from_grid(board):\n",
    "    \"\"\"\n",
    "    Synthetic scoring: higher average letter → higher score.\n",
    "    \"\"\"\n",
    "    nonzero = board[board > 0]\n",
    "    if len(nonzero) == 0:\n",
    "        return 0\n",
    "    avg_value = np.mean(nonzero)\n",
    "    filled = len(nonzero)\n",
    "    vowels = sum(chr(int(x) + 64) in \"AEIOU\" for x in nonzero)\n",
    "    return 0.3 * filled + 0.4 * vowels + 0.3 * avg_value + random.uniform(0, 5)\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "boards = np.array([generate_board_grid() for _ in range(N_SAMPLES)])\n",
    "y = np.array([estimate_score_from_grid(board) for board in boards])\n",
    "\n",
    "X = boards / 26.0\n",
    "y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "X = X.reshape((N_SAMPLES, 15, 15))\n",
    "\n",
    "print(\"✅ Data shape:\", X.shape, y.shape)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, 15), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='tanh'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X, y, epochs=20, batch_size=16, validation_split=0.1)\n",
    "print(\"✅ Training complete.\")\n",
    "\n",
    "model.save(\"model/model_weights_lstm.h5\")\n",
    "print(\"✅ LSTM model saved to model/model_weights_lstm.h5\")\n",
    "\n",
    "tokenizer = {ch: i+1 for i, ch in enumerate(letters)}\n",
    "with open(\"model/tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(\"✅ Tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7758d-0b7f-416e-acca-b503aa61bb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
